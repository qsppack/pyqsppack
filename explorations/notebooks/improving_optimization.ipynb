{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba364fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 16\n",
      "Time: 0.3235609531402588\n",
      "Final: 1.030339717544848e-06\n",
      "# Iterations: 71\n",
      "-----------------------------------------------------\n",
      "N: 32\n",
      "Time: 1.238006830215454\n",
      "Final: 4.154373164055869e-05\n",
      "# Iterations: 201\n",
      "-----------------------------------------------------\n",
      "N: 64\n",
      "Time: 3.0356409549713135\n",
      "Final: 3.266644199584334e-08\n",
      "# Iterations: 435\n",
      "-----------------------------------------------------\n",
      "N: 128\n",
      "Time: 4.42612099647522\n",
      "Final: 6.429892891901545e-06\n",
      "# Iterations: 641\n",
      "-----------------------------------------------------\n",
      "N: 256\n",
      "Time: 6.6678760051727295\n",
      "Final: 5.054324446973624e-06\n",
      "# Iterations: 880\n",
      "-----------------------------------------------------\n",
      "N: 512\n",
      "Time: 4.485189914703369\n",
      "Final: 5.584213795373216e-06\n",
      "# Iterations: 587\n",
      "-----------------------------------------------------\n",
      "N: 1024\n",
      "Time: 9.548364162445068\n",
      "Final: 2.3808004243619507e-06\n",
      "# Iterations: 1000\n",
      "-----------------------------------------------------\n",
      "N: 2048\n",
      "Time: 9.351141214370728\n",
      "Final: 3.6368119253893383e-06\n",
      "# Iterations: 1000\n",
      "-----------------------------------------------------\n",
      "N: 4096\n",
      "Time: 9.589447975158691\n",
      "Final: 4.910428287985269e-06\n",
      "# Iterations: 563\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     48\u001b[39m     loss.backward()\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m optimizer.step(closure)\n\u001b[32m     53\u001b[39m t1 = time.time()\n\u001b[32m     55\u001b[39m total = t1-t0\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qspy-py311/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    380\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    381\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    382\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    383\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m out = func(*args, **kwargs)\n\u001b[32m    386\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qspy-py311/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/qspy-py311/lib/python3.11/site-packages/torch/optim/lbfgs.py:391\u001b[39m, in \u001b[36mLBFGS.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    389\u001b[39m     d = r = torch.mul(q, H_diag)\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_old):\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m         be_i = old_dirs[i].dot(r) * ro[i]\n\u001b[32m    392\u001b[39m         r.add_(old_stps[i], alpha=al[i] - be_i)\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prev_flat_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import conv1d, pad\n",
    "from torch.fft import fft\n",
    "from torchaudio.transforms import FFTConvolve\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Use CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def objective_torch(x, P):\n",
    "    x.requires_grad = True\n",
    "\n",
    "    # Compute loss using squared distance function\n",
    "    loss = torch.norm(P - FFTConvolve(\"full\").forward(x, torch.flip(x, dims=[0])))**2\n",
    "    return loss\n",
    "\n",
    "times = []\n",
    "final_vals = []\n",
    "num_iterations = []\n",
    "\n",
    "for k in range(4, 20):\n",
    "    N = 2 ** k\n",
    "    poly = torch.randn(N, device=device)\n",
    "\n",
    "    granularity = 2 ** 25\n",
    "    P = pad(poly, (0, granularity - poly.shape[0]))\n",
    "    ft = fft(P)\n",
    "\n",
    "    # Normalize P\n",
    "    P_norms = ft.abs()\n",
    "    poly /= torch.max(P_norms)\n",
    "\n",
    "    conv_p_negative = FFTConvolve(\"full\").forward(poly, torch.flip(poly, dims=[0]))* -1\n",
    "    conv_p_negative[poly.shape[0] - 1] = 1 - torch.norm(poly) ** 2\n",
    "\n",
    "    # Initializing Q randomly to start with\n",
    "    initial = torch.randn(poly.shape[0], device=device, requires_grad=True)\n",
    "    initial = (initial / torch.norm(initial)).clone().detach().requires_grad_(True)\n",
    "\n",
    "    optimizer = torch.optim.LBFGS([initial], max_iter=1000)\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss = objective_torch(initial, conv_p_negative)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    total = t1-t0\n",
    "    times.append(total)\n",
    "    final_vals.append(closure().item())\n",
    "    num_iterations.append(optimizer.state[optimizer._params[0]]['n_iter'])\n",
    "    print(f'N: {N}')\n",
    "    print(f'Time: {total}')\n",
    "    print(f'Final: {closure().item()}')\n",
    "    print(f\"# Iterations: {optimizer.state[optimizer._params[0]]['n_iter']}\")\n",
    "    print(\"-----------------------------------------------------\")\n",
    "\n",
    "print(times)\n",
    "print(final_vals)\n",
    "print(num_iterations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qspy-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
